"""
Streamlit UI - AI Image Filter Pipeline
"""

import streamlit as st
import requests
import pandas as pd
from PIL import Image
import io
import time
from datetime import datetime

# ============ ì„¤ì • ============
API_URL = "http://localhost:8000/api/v1"  # FastAPI ì„œë²„ ì£¼ì†Œ

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI Image Filter Pipeline",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============ CSS ìŠ¤íƒ€ì¼ ============
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .verdict-ai {
        background-color: #ffcccb;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #dc3545;
    }
    .verdict-real {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #28a745;
    }
    .verdict-uncertain {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #ffc107;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)


def main():
    # í—¤ë”
    st.markdown('<p class="main-header">ğŸ” AI Image Filter Pipeline</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ML í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ AI ìƒì„± ì´ë¯¸ì§€ë¥¼ í•„í„°ë§í•˜ëŠ” 3-Layer ê²€ì¦ ì‹œìŠ¤í…œ</p>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        api_url = st.text_input("API URL", value=API_URL)
        skip_ai_detection = st.checkbox("AI íƒì§€ ìŠ¤í‚µ (ë¹ ë¥¸ ë¶„ì„)", value=False)
        
        st.divider()
        
        st.header("ğŸ“Š ë¶„ì„ íŒŒì´í”„ë¼ì¸")
        st.markdown("""
        **Layer 1**: Hash Check  
        **Layer 2**: Metadata Analysis  
        **Layer 3**: AI Detection([HuggingFace](https://huggingface.co/dima806/ai_vs_human_generated_image_detection))
        """)
        st.info("â„¹ï¸ Stateless ëª¨ë“œ - ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ë¶„ì„ì€ ì‹¤ì‹œê°„ìœ¼ë¡œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        
        st.divider()
        

    
    # ë©”ì¸ íƒ­
    tab1, tab2 = st.tabs(["ğŸ“¤ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„", "ğŸ“¦ ë°°ì¹˜ ë¶„ì„"])
    
    # ============ íƒ­ 1: ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ ============
    with tab1:
        st.header("ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„")
        
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png", "webp", "gif"],
            key="single_upload"
        )
        
        if uploaded_file:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("ğŸ“· ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
                image = Image.open(uploaded_file)
                st.image(image, use_container_width=True)
                st.caption(f"íŒŒì¼ëª…: {uploaded_file.name} | í¬ê¸°: {uploaded_file.size:,} bytes")
            
            with col2:
                st.subheader("ğŸ”¬ ë¶„ì„ ê²°ê³¼")
                
                if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", key="analyze_single"):
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        try:
                            # API í˜¸ì¶œ
                            uploaded_file.seek(0)
                            files = {"file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
                            params = {"skip_ai_detection": skip_ai_detection}
                            
                            response = requests.post(
                                f"{api_url}/analyze",
                                files=files,
                                params=params,
                                timeout=60
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                display_result(result)
                            else:
                                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {response.text}")
                                
                        except requests.exceptions.ConnectionError:
                            st.error("âš ï¸ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                            st.info("ë¡œì»¬ í…ŒìŠ¤íŠ¸: `uvicorn app.main:app --reload`")
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ============ íƒ­ 2: ë°°ì¹˜ ë¶„ì„ ============
    with tab2:
        st.header("ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„")
        st.info("ìµœëŒ€ 50ê°œ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        uploaded_files = st.file_uploader(
            "ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png", "webp"],
            accept_multiple_files=True,
            key="batch_upload"
        )
        
        if uploaded_files:
            st.write(f"ğŸ“ {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")
            
            if st.button("ğŸš€ ë°°ì¹˜ ë¶„ì„ ì‹œì‘", type="primary", key="analyze_batch"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                results = []
                
                for i, file in enumerate(uploaded_files):
                    status_text.text(f"ë¶„ì„ ì¤‘: {file.name} ({i+1}/{len(uploaded_files)})")
                    
                    try:
                        file.seek(0)
                        files = {"file": (file.name, file.getvalue(), file.type)}
                        params = {"skip_ai_detection": skip_ai_detection}
                        
                        response = requests.post(
                            f"{api_url}/analyze",
                            files=files,
                            params=params,
                            timeout=60
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            results.append({
                                "íŒŒì¼ëª…": file.name,
                                "íŒì •": result.get("final_verdict", "unknown"),
                                "í™•ì‹ ë„": f"{result.get('confidence_score', 0):.1%}",
                                "AI ì‹œê·¸ë‹ˆì²˜": ", ".join(result.get("metadata_result", {}).get("ai_tool_signatures", [])) or "-"
                            })
                        else:
                            results.append({
                                "íŒŒì¼ëª…": file.name,
                                "íŒì •": "error",
                                "í™•ì‹ ë„": "-",
                                "AI ì‹œê·¸ë‹ˆì²˜": "-"
                            })
                    except Exception as e:
                        results.append({
                            "íŒŒì¼ëª…": file.name,
                            "íŒì •": "error",
                            "í™•ì‹ ë„": "-",
                            "AI ì‹œê·¸ë‹ˆì²˜": str(e)[:50]
                        })
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                # ê²°ê³¼ í…Œì´ë¸”
                df = pd.DataFrame(results)
                st.dataframe(df, use_container_width=True)
                
                # í†µê³„
                col1, col2, col3 = st.columns(3)
                ai_count = sum(1 for r in results if r["íŒì •"] == "ai_generated")
                real_count = sum(1 for r in results if r["íŒì •"] == "likely_real")
                uncertain_count = sum(1 for r in results if r["íŒì •"] == "uncertain")
                
                col1.metric("ğŸ¤– AI ìƒì„±", ai_count)
                col2.metric("âœ… ì‹¤ì œ ì´ë¯¸ì§€", real_count)
                col3.metric("â“ ë¶ˆí™•ì‹¤", uncertain_count)
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    "ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    csv,
                    f"ai_filter_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    "text/csv"
                )
    



def display_result(result: dict):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    verdict = result.get("final_verdict", "unknown")
    confidence = result.get("confidence_score", 0)
    
    # íŒì • ê²°ê³¼ í‘œì‹œ
    if verdict == "ai_generated":
        st.markdown(f"""
        <div class="verdict-ai">
            <h3>ğŸ¤– AI ìƒì„± ì´ë¯¸ì§€ë¡œ íŒì •</h3>
            <p>í™•ì‹ ë„: <strong>{confidence:.1%}</strong></p>
        </div>
        """, unsafe_allow_html=True)
    elif verdict == "likely_real":
        st.markdown(f"""
        <div class="verdict-real">
            <h3>âœ… ì‹¤ì œ ì´ë¯¸ì§€ë¡œ íŒì •</h3>
            <p>í™•ì‹ ë„: <strong>{confidence:.1%}</strong></p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="verdict-uncertain">
            <h3>â“ íŒì • ë¶ˆí™•ì‹¤</h3>
            <p>í™•ì‹ ë„: <strong>{confidence:.1%}</strong></p>
        </div>
        """, unsafe_allow_html=True)
    
    st.divider()
    
    # ìƒì„¸ ê²°ê³¼
    with st.expander("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼", expanded=True):
        # íŒì • ê·¼ê±°
        st.subheader("íŒì • ê·¼ê±°")
        reasoning = result.get("reasoning", "")
        for reason in reasoning.split(" | "):
            st.write(f"â€¢ {reason}")
        
        st.divider()
        
        # Layer 1: Hash
        st.subheader("Layer 1: Hash Check")
        hash_result = result.get("hash_result", {})
        col1, col2 = st.columns(2)
        col1.code(f"MD5: {hash_result.get('md5', 'N/A')}")
        col2.code(f"SHA256: {hash_result.get('sha256', 'N/A')[:32]}...")
        if hash_result.get("is_duplicate"):
            st.warning("âš ï¸ ì¤‘ë³µ ì´ë¯¸ì§€ ë°œê²¬")
        
        st.divider()
        
        # Layer 2: Metadata
        st.subheader("Layer 2: Metadata Analysis")
        metadata = result.get("metadata_result", {})
        
        if metadata.get("has_c2pa"):
            st.success("ğŸ“œ C2PA Content Credentials ë°œê²¬")
        
        if metadata.get("ai_tool_signatures"):
            st.warning(f"ğŸ” AI ë„êµ¬ ì‹œê·¸ë‹ˆì²˜: {', '.join(metadata['ai_tool_signatures'])}")
        
        if metadata.get("software_used"):
            st.info(f"ğŸ’» ì†Œí”„íŠ¸ì›¨ì–´: {metadata['software_used']}")
        
        if metadata.get("exif_data"):
            with st.expander("EXIF ë°ì´í„°"):
                st.json(metadata["exif_data"])
        
        st.divider()
        
        # Layer 3: AI Detection
        st.subheader("Layer 3: AI Detection")
        detection = result.get("detection_result")
        if detection:
            st.write(f"**ëª¨ë¸**: {detection.get('model_name', 'N/A')}")
            st.write(f"**AI ìƒì„± íŒì •**: {'ì˜ˆ' if detection.get('is_ai_generated') else 'ì•„ë‹ˆì˜¤'}")
            st.write(f"**í™•ì‹ ë„**: {detection.get('confidence', 0):.1%}")
            
            if detection.get("raw_scores"):
                st.write("**Raw Scores:**")
                for label, score in detection["raw_scores"].items():
                    st.progress(score, text=f"{label}: {score:.1%}")
        else:
            st.info("AI íƒì§€ ìŠ¤í‚µë¨")
    
    # ì‹¤í–‰ ì‹œê°„
    st.caption(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {result.get('total_execution_time_ms', 0):.0f}ms")


if __name__ == "__main__":
    main()
